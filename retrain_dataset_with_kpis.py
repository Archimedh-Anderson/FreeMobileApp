"""
Script de Retraining du Dataset avec KPIs Enrichis
===================================================

Ce script retraine le dataset d'entraÃ®nement avec:
1. Correction des valeurs de rÃ©clamation (Oui/Non â†’ valeurs prÃ©cises)
2. Ajout de "ThÃ¨me principal" avec classification score-based  
3. Ajout de "Incident principal" avec mapping de responsabilitÃ©
4. Calcul de statistiques (Count, Percentage) pour chaque catÃ©gorie
5. Export du dataset enrichi avec mÃ©triques de qualitÃ©

BasÃ© sur la logique de classification de dynamic_classifier.py
"""

import pandas as pd
import numpy as np
import re
from typing import Dict, List, Tuple
from collections import Counter
import json
from datetime import datetime
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class EnhancedThemeClassifier:
    """Classificateur de thÃ¨me basÃ© sur score de mots-clÃ©s (pas de first-match)"""
    
    THEME_KEYWORDS = {
        'FIBRE': [
            'fibre', 'ftth', 'internet', 'dÃ©bit', 'connexion', 'ligne', 'rÃ©seau',
            'box', 'freebox', 'adsl', 'vdsl', 'wifi', 'sans fil', 'routeur',
            'installation', 'technicien', 'cÃ¢ble', 'prise', 'Ã©tape'
        ],
        'MOBILE': [
            'mobile', 'tÃ©lÃ©phone', 'forfait', '4g', '5g', 'data', 'appel', 'sms',
            'carte sim', 'rÃ©seau mobile', 'couverture', 'signal', 'antenne'
        ],
        'TV': [
            'tv', 'tÃ©lÃ©vision', 'chaÃ®ne', 'programme', 'replay', 'streaming',
            'chaines', 'player', 'dÃ©codeur', 'image', 'son', 'vidÃ©o'
        ],
        'FACTURE': [
            'facture', 'facturation', 'prix', 'coÃ»t', 'tarif', 'paiement',
            'prÃ©lÃ¨vement', 'abonnement', 'euro', 'eur', 'rembours', 'crÃ©dit',
            'dÃ©bit', 'montant', 'gratuit', 'payant'
        ],
        'SAV': [
            'sav', 'service client', 'support', 'assistance', 'conseiller',
            'contact', 'rÃ©ponse', 'appel', '3244', 'messenger', 'whatsapp',
            'ticket', 'dossier', 'suivi', 'relance'
        ],
        'RESEAU': [
            'panne', 'coupure', 'interruption', 'bug', 'problÃ¨me', 'incident',
            'dysfonctionnement', 'erreur', 'dÃ©faillance', 'perturbation',
            'instable', 'lent', 'slow'
        ],
        'ACTIVATION': [
            'activation', 'activer', 'mise en service', 'installation', 
            'raccordement', 'branchement', 'rendez-vous', 'technicien'
        ],
        'RESILIATION': [
            'rÃ©siliation', 'rÃ©silier', 'annulation', 'arrÃªt', 'fin', 'quitter',
            'partir', 'changer', 'concurrent', 'restitution'
        ]
    }
    
    def classify(self, text: str) -> Tuple[str, float, List[str]]:
        """Classifie le thÃ¨me basÃ© sur le score de mots-clÃ©s (mÃ©thode score-based)"""
        text_lower = text.lower()
        theme_scores = {}
        matched_keywords = {}
        
        # Calculer le score pour chaque thÃ¨me
        for theme, keywords in self.THEME_KEYWORDS.items():
            score = 0
            matches = []
            for keyword in keywords:
                if keyword in text_lower:
                    score += 1
                    matches.append(keyword)
            
            if score > 0:
                theme_scores[theme] = score
                matched_keywords[theme] = matches
        
        # Si aucun mot-clÃ© dÃ©tectÃ©, retourner "autre"
        if not theme_scores:
            return 'autre', 0.5, []
        
        # SÃ©lectionner le thÃ¨me avec le score le plus Ã©levÃ© (pas le premier match!)
        best_theme = max(theme_scores, key=theme_scores.get)
        max_score = theme_scores[best_theme]
        
        # Calculer la confiance basÃ©e sur le nombre de mots-clÃ©s
        if max_score >= 3:
            confidence = 0.90
        elif max_score == 2:
            confidence = 0.85
        else:
            confidence = 0.75
        
        return best_theme, confidence, matched_keywords.get(best_theme, [])


class IncidentClassifier:
    """Classificateur d'incident avec mapping de responsabilitÃ©"""
    
    INCIDENT_PATTERNS = {
        'facturation': {
            'keywords': ['facture', 'facturation', 'prix', 'coÃ»t', 'tarif', 'prÃ©lÃ¨vement', 
                        'paiement', 'rembours', 'crÃ©dit', 'dÃ©bit', 'montant'],
            'responsable': 'service_commercial'
        },
        'incident_reseau': {
            'keywords': ['panne', 'coupure', 'interruption', 'bug', 'erreur', 'problÃ¨me',
                        'dysfonctionnement', 'dÃ©faillance', 'perturbation', 'instable'],
            'responsable': 'service_technique'
        },
        'livraison': {
            'keywords': ['livraison', 'colis', 'livrÃ©', 'rÃ©ception', 'envoi', 'retour',
                        'restitution', 'matÃ©riel'],
            'responsable': 'service_logistique'
        },
        'information': {
            'keywords': ['information', 'savoir', 'connaitre', 'question', 'demande',
                        'comment', 'pourquoi', 'quand', 'quel'],
            'responsable': 'service_client'
        },
        'processus_sav': {
            'keywords': ['sav', 'support', 'assistance', 'conseiller', 'contact', 
                        'rÃ©ponse', 'ticket', 'dossier', 'suivi', 'relance'],
            'responsable': 'service_client'
        },
        'technique': {
            'keywords': ['installation', 'configuration', 'paramÃ¨tre', 'wifi', 'routeur',
                        'box', 'branchement', 'cÃ¢ble', 'technicien'],
            'responsable': 'service_technique'
        }
    }
    
    def classify(self, text: str) -> Tuple[str, str, float]:
        """Classifie l'incident et dÃ©termine le responsable"""
        text_lower = text.lower()
        incident_scores = {}
        
        # Calculer le score pour chaque type d'incident
        for incident_type, config in self.INCIDENT_PATTERNS.items():
            score = sum(1 for keyword in config['keywords'] if keyword in text_lower)
            if score > 0:
                incident_scores[incident_type] = score
        
        # Si aucun pattern dÃ©tectÃ©, retourner "aucun"
        if not incident_scores:
            return 'aucun', 'service_client', 0.5
        
        # SÃ©lectionner l'incident avec le score le plus Ã©levÃ©
        best_incident = max(incident_scores, key=incident_scores.get)
        max_score = incident_scores[best_incident]
        responsable = self.INCIDENT_PATTERNS[best_incident]['responsable']
        
        # Calculer la confiance
        confidence = min(0.5 + (max_score * 0.15), 0.95)
        
        return best_incident, responsable, confidence


class ReclamationClassifier:
    """Classificateur de rÃ©clamation (Oui/Non) basÃ© sur intention"""
    
    RECLAMATION_KEYWORDS = [
        'problÃ¨me', 'panne', 'bug', 'erreur', 'dysfonctionnement',
        'insatisfait', 'mÃ©content', 'dÃ©Ã§u', 'inacceptable', 'inadmissible',
        'scandaleux', 'honteux', 'nul', 'mauvais', 'pire', 'catastrophique',
        'ras le bol', 'en avoir marre', 'rÃ©silier', 'partir', 'concurrent'
    ]
    
    NEGATIVE_SENTIMENT_KEYWORDS = [
        'pas', 'plus', 'aucun', 'jamais', 'rien', 'impossible', 'incapable',
        'toujours pas', 'encore', 'depuis', 'jours', 'semaine', 'mois'
    ]
    
    def classify(self, text: str) -> Tuple[str, float]:
        """DÃ©termine si le tweet est une rÃ©clamation (Oui/Non)"""
        text_lower = text.lower()
        
        # Compter les mots-clÃ©s de rÃ©clamation
        reclamation_score = sum(1 for keyword in self.RECLAMATION_KEYWORDS 
                               if keyword in text_lower)
        
        # Compter les marqueurs de sentiment nÃ©gatif
        negative_score = sum(1 for keyword in self.NEGATIVE_SENTIMENT_KEYWORDS 
                            if keyword in text_lower)
        
        # Score total
        total_score = reclamation_score + (negative_score * 0.5)
        
        # DÃ©cision
        if total_score >= 2.0:
            return 'Oui', min(0.6 + (total_score * 0.1), 0.95)
        elif total_score >= 1.0:
            return 'Oui', 0.7
        else:
            return 'Non', 0.6


def retrain_dataset_with_enhanced_kpis(input_csv: str, output_csv: str):
    """
    Retraine le dataset avec les nouvelles colonnes KPI
    
    Args:
        input_csv: Chemin vers train_dataset.csv
        output_csv: Chemin vers le dataset enrichi
    """
    logger.info(f"Chargement du dataset: {input_csv}")
    
    # Charger le dataset
    df = pd.read_csv(input_csv)
    initial_count = len(df)
    logger.info(f"Dataset chargÃ©: {initial_count} lignes")
    
    # Initialiser les classificateurs
    theme_clf = EnhancedThemeClassifier()
    incident_clf = IncidentClassifier()
    reclamation_clf = ReclamationClassifier()
    
    # CrÃ©er les nouvelles colonnes
    logger.info("Classification en cours...")
    
    themes = []
    theme_confidences = []
    incidents = []
    incident_responsables = []
    incident_confidences = []
    reclamations = []
    reclamation_confidences = []
    
    for idx, row in df.iterrows():
        text = str(row.get('text_cleaned', row.get('text', '')))
        
        # Classification du thÃ¨me
        theme, theme_conf, _ = theme_clf.classify(text)
        themes.append(theme)
        theme_confidences.append(theme_conf)
        
        # Classification de l'incident
        incident, responsable, inc_conf = incident_clf.classify(text)
        incidents.append(incident)
        incident_responsables.append(responsable)
        incident_confidences.append(inc_conf)
        
        # Classification de rÃ©clamation
        is_reclamation, rec_conf = reclamation_clf.classify(text)
        reclamations.append(is_reclamation)
        reclamation_confidences.append(rec_conf)
        
        if (idx + 1) % 500 == 0:
            logger.info(f"TraitÃ© {idx + 1}/{initial_count} lignes...")
    
    # Ajouter les nouvelles colonnes
    df['ThÃ¨me principal'] = themes
    df['theme_confidence'] = theme_confidences
    df['Incident principal'] = incidents
    df['incident_responsable'] = incident_responsables
    df['incident_confidence'] = incident_confidences
    df['rÃ©clamations'] = reclamations  # Remplacer l'ancienne colonne
    df['reclamation_confidence'] = reclamation_confidences
    
    logger.info("Classification terminÃ©e")
    
    # Calculer les statistiques KPI
    logger.info("Calcul des statistiques KPI...")
    
    kpi_stats = {
        'total_tweets': len(df),
        'date_traitement': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        
        'themes': {},
        'incidents': {},
        'reclamations': {},
        'responsables': {}
    }
    
    # Statistiques par thÃ¨me
    theme_counts = df['ThÃ¨me principal'].value_counts()
    for theme, count in theme_counts.items():
        percentage = (count / len(df)) * 100
        kpi_stats['themes'][theme] = {
            'count': int(count),
            'percentage': round(percentage, 2),
            'avg_confidence': round(df[df['ThÃ¨me principal'] == theme]['theme_confidence'].mean(), 2)
        }
    
    # Statistiques par incident
    incident_counts = df['Incident principal'].value_counts()
    for incident, count in incident_counts.items():
        percentage = (count / len(df)) * 100
        kpi_stats['incidents'][incident] = {
            'count': int(count),
            'percentage': round(percentage, 2),
            'avg_confidence': round(df[df['Incident principal'] == incident]['incident_confidence'].mean(), 2)
        }
    
    # Statistiques rÃ©clamations
    reclamation_counts = df['rÃ©clamations'].value_counts()
    for reclamation, count in reclamation_counts.items():
        percentage = (count / len(df)) * 100
        kpi_stats['reclamations'][reclamation] = {
            'count': int(count),
            'percentage': round(percentage, 2)
        }
    
    # Statistiques par responsable
    responsable_counts = df['incident_responsable'].value_counts()
    for responsable, count in responsable_counts.items():
        percentage = (count / len(df)) * 100
        kpi_stats['responsables'][responsable] = {
            'count': int(count),
            'percentage': round(percentage, 2)
        }
    
    # Sauvegarder le dataset enrichi
    logger.info(f"Sauvegarde du dataset enrichi: {output_csv}")
    df.to_csv(output_csv, index=False, encoding='utf-8')
    
    # Sauvegarder les statistiques KPI
    stats_file = output_csv.replace('.csv', '_kpi_stats.json')
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(kpi_stats, f, indent=2, ensure_ascii=False)
    
    logger.info(f"Statistiques KPI sauvegardÃ©es: {stats_file}")
    
    # Afficher un rÃ©sumÃ©
    print("\n" + "="*80)
    print("ðŸ“Š RÃ‰SUMÃ‰ DU RETRAINING - DATASET ENRICHI")
    print("="*80)
    print(f"\nâœ… Dataset original: {initial_count} lignes")
    print(f"âœ… Dataset enrichi: {len(df)} lignes")
    print(f"âœ… Nouvelles colonnes ajoutÃ©es: 7")
    
    print("\nðŸ“ˆ DISTRIBUTION DES THÃˆMES PRINCIPAUX:")
    for theme, stats in sorted(kpi_stats['themes'].items(), key=lambda x: x[1]['count'], reverse=True):
        print(f"   â€¢ {theme:20s}: {stats['count']:5d} tweets ({stats['percentage']:5.2f}%) - Conf: {stats['avg_confidence']:.2f}")
    
    print("\nðŸ”§ DISTRIBUTION DES INCIDENTS PRINCIPAUX:")
    for incident, stats in sorted(kpi_stats['incidents'].items(), key=lambda x: x[1]['count'], reverse=True):
        print(f"   â€¢ {incident:20s}: {stats['count']:5d} tweets ({stats['percentage']:5.2f}%) - Conf: {stats['avg_confidence']:.2f}")
    
    print("\nðŸ“‹ DISTRIBUTION DES RÃ‰CLAMATIONS:")
    for reclamation, stats in kpi_stats['reclamations'].items():
        print(f"   â€¢ {reclamation:20s}: {stats['count']:5d} tweets ({stats['percentage']:5.2f}%)")
    
    print("\nðŸ‘¥ DISTRIBUTION PAR RESPONSABLE:")
    for responsable, stats in sorted(kpi_stats['responsables'].items(), key=lambda x: x[1]['count'], reverse=True):
        print(f"   â€¢ {responsable:25s}: {stats['count']:5d} tweets ({stats['percentage']:5.2f}%)")
    
    print("\n" + "="*80)
    print(f"âœ… Dataset enrichi sauvegardÃ©: {output_csv}")
    print(f"âœ… Statistiques KPI sauvegardÃ©es: {stats_file}")
    print("="*80 + "\n")
    
    return df, kpi_stats


if __name__ == "__main__":
    # Chemins des fichiers
    INPUT_CSV = "data/training/train_dataset.csv"
    OUTPUT_CSV = "data/training/train_dataset_enriched.csv"
    
    # ExÃ©cuter le retraining
    df_enriched, kpi_stats = retrain_dataset_with_enhanced_kpis(INPUT_CSV, OUTPUT_CSV)
    
    print("ðŸŽ‰ Retraining terminÃ© avec succÃ¨s!")
    print(f"\nðŸ“‚ Fichiers gÃ©nÃ©rÃ©s:")
    print(f"   â€¢ Dataset enrichi: {OUTPUT_CSV}")
    print(f"   â€¢ Statistiques KPI: {OUTPUT_CSV.replace('.csv', '_kpi_stats.json')}")
