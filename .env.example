# ============================================================================
# Configuration des Providers de Classification
# ============================================================================
# Copiez ce fichier vers .env et remplissez les valeurs appropriées
# cp .env.example .env

# ============================================================================
# Gemini API Configuration (Google Cloud)
# ============================================================================
# Clé API pour Google Gemini API
# 
# Pour obtenir une clé API:
# 1. Créez un compte Google Cloud: https://console.cloud.google.com
# 2. Générez une clé API: https://ai.google.dev/api
# 3. Copiez votre clé ci-dessous
#
# OU configurez-la via le sidebar de l'application: 
# Sidebar -> Configuration Provider -> Gemini API
#
GEMINI_API_KEY=your_api_key_here

# Alternative: utiliser GOOGLE_API_KEY au lieu de GEMINI_API_KEY
# GOOGLE_API_KEY=your_api_key_here

# ============================================================================
# Mistral Local (Ollama) - Configuration Optionnelle
# ============================================================================
# URL du serveur Ollama local (par défaut: http://localhost:11434)
# Ne modifiez que si Ollama est installé sur un autre serveur/port
#
OLLAMA_URL=http://localhost:11434

# Nom du modèle Mistral à utiliser (par défaut: mistral)
# Liste des modèles disponibles: ollama list
# Modèles recommandés: mistral, mistral:7b, mistral:latest
#
OLLAMA_MODEL=mistral
