"""
Tests Unitaires pour les Fonctions Critiques
FreeMobilaChat v4.5 Final Edition
"""

import pytest
import pandas as pd
import sys
import os

# Ajouter le chemin du projet
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))


class TestFileHandling:
    """Tests pour la gestion des fichiers"""
    
    def test_csv_detection(self):
        """Test: DÃ©tection du format CSV"""
        # Simuler un nom de fichier CSV
        filename = "test_data.csv"
        assert filename.endswith('.csv'), "Le fichier devrait Ãªtre reconnu comme CSV"
    
    def test_excel_detection(self):
        """Test: DÃ©tection du format Excel"""
        filenames = ["test.xlsx", "test.xls"]
        for filename in filenames:
            assert filename.endswith(('.xlsx', '.xls')), f"{filename} devrait Ãªtre reconnu comme Excel"
    
    def test_json_detection(self):
        """Test: DÃ©tection du format JSON"""
        filename = "test_data.json"
        assert filename.endswith('.json'), "Le fichier devrait Ãªtre reconnu comme JSON"
    
    def test_file_size_validation(self):
        """Test: Validation de la taille du fichier (< 500 MB)"""
        max_size_mb = 500
        max_size_bytes = max_size_mb * 1024 * 1024
        
        # Test cas valide
        test_size_valid = 100 * 1024 * 1024  # 100 MB
        assert test_size_valid < max_size_bytes, "100 MB devrait Ãªtre acceptÃ©"
        
        # Test cas invalide
        test_size_invalid = 600 * 1024 * 1024  # 600 MB
        assert test_size_invalid > max_size_bytes, "600 MB devrait Ãªtre refusÃ©"


class TestDataValidation:
    """Tests pour la validation des donnÃ©es"""
    
    def test_empty_dataframe_detection(self):
        """Test: DÃ©tection d'un DataFrame vide"""
        df_empty = pd.DataFrame()
        assert df_empty.empty, "DataFrame vide devrait Ãªtre dÃ©tectÃ©"
        
        df_not_empty = pd.DataFrame({'col': [1, 2, 3]})
        assert not df_not_empty.empty, "DataFrame avec donnÃ©es devrait Ãªtre dÃ©tectÃ©"
    
    def test_required_columns_validation(self):
        """Test: Validation des colonnes requises"""
        df = pd.DataFrame({
            'text': ['Tweet 1', 'Tweet 2', 'Tweet 3'],
            'sentiment': ['positive', 'negative', 'neutral']
        })
        
        # VÃ©rifier la prÃ©sence d'au moins une colonne texte
        text_columns = [col for col in df.columns if df[col].dtype == 'object']
        assert len(text_columns) > 0, "Au moins une colonne texte devrait exister"
    
    def test_data_types_validation(self):
        """Test: Validation des types de donnÃ©es"""
        df = pd.DataFrame({
            'text': ['Tweet 1', 'Tweet 2'],
            'count': [10, 20]
        })
        
        assert df['text'].dtype == 'object', "Colonne texte devrait Ãªtre de type object"
        assert df['count'].dtype in ['int64', 'int32'], "Colonne count devrait Ãªtre numÃ©rique"
    
    def test_null_values_detection(self):
        """Test: DÃ©tection des valeurs nulles"""
        df = pd.DataFrame({
            'text': ['Tweet 1', None, 'Tweet 3'],
            'sentiment': ['positive', 'negative', None]
        })
        
        null_counts = df.isnull().sum()
        assert null_counts['text'] == 1, "Une valeur nulle devrait Ãªtre dÃ©tectÃ©e dans 'text'"
        assert null_counts['sentiment'] == 1, "Une valeur nulle devrait Ãªtre dÃ©tectÃ©e dans 'sentiment'"


class TestMetricsCalculation:
    """Tests pour le calcul des mÃ©triques"""
    
    def test_reclamations_count(self):
        """Test: Comptage des rÃ©clamations"""
        df = pd.DataFrame({
            'is_claim': ['oui', 'non', 'oui', 'oui', 'non']
        })
        
        reclamations_count = len(df[df['is_claim'] == 'oui'])
        assert reclamations_count == 3, "3 rÃ©clamations devraient Ãªtre comptÃ©es"
    
    def test_reclamations_percentage(self):
        """Test: Calcul du pourcentage de rÃ©clamations"""
        df = pd.DataFrame({
            'is_claim': ['oui', 'non', 'oui', 'oui', 'non']
        })
        
        reclamations_count = len(df[df['is_claim'] == 'oui'])
        total_count = len(df)
        percentage = (reclamations_count / total_count) * 100
        
        assert percentage == 60.0, "Le pourcentage devrait Ãªtre 60%"
    
    def test_sentiment_distribution(self):
        """Test: Distribution des sentiments"""
        df = pd.DataFrame({
            'sentiment': ['positive', 'negative', 'neutral', 'positive', 'negative']
        })
        
        sentiment_counts = df['sentiment'].value_counts()
        
        assert sentiment_counts['positive'] == 2, "2 sentiments positifs"
        assert sentiment_counts['negative'] == 2, "2 sentiments nÃ©gatifs"
        assert sentiment_counts['neutral'] == 1, "1 sentiment neutre"
    
    def test_confidence_score_calculation(self):
        """Test: Calcul du score de confiance"""
        scores = [0.95, 0.88, 0.92, 0.85, 0.90]
        avg_confidence = sum(scores) / len(scores)
        
        assert 0.88 <= avg_confidence <= 0.92, "La confiance moyenne devrait Ãªtre entre 0.88 et 0.92"
        assert round(avg_confidence, 2) == 0.90, "La confiance moyenne devrait Ãªtre 0.90"


class TestTextCleaning:
    """Tests pour le nettoyage de texte"""
    
    def test_url_removal(self):
        """Test: Suppression des URLs"""
        text = "Consultez https://example.com pour plus d'infos"
        # Simulation de nettoyage URL
        import re
        cleaned = re.sub(r'https?://\S+', '', text)
        
        assert 'https://' not in cleaned, "Les URLs devraient Ãªtre supprimÃ©es"
        assert 'example.com' not in cleaned, "Les domaines devraient Ãªtre supprimÃ©s"
    
    def test_mention_handling(self):
        """Test: Gestion des mentions Twitter"""
        text = "@user1 Merci pour votre aide @user2"
        # Simulation de nettoyage mentions
        import re
        cleaned = re.sub(r'@\w+', '', text)
        
        assert '@user1' not in cleaned, "Les mentions devraient Ãªtre supprimÃ©es"
        assert '@user2' not in cleaned, "Les mentions devraient Ãªtre supprimÃ©es"
    
    def test_special_characters_removal(self):
        """Test: Suppression des caractÃ¨res spÃ©ciaux"""
        text = "Texte avec #hashtag et Ã©moticÃ´nes ðŸ˜Š"
        
        # Les hashtags et emojis devraient Ãªtre traitÃ©s
        assert '#hashtag' in text, "Le texte original contient des hashtags"
    
    def test_lowercase_conversion(self):
        """Test: Conversion en minuscules"""
        text = "TEXTE EN MAJUSCULES"
        cleaned = text.lower()
        
        assert cleaned == "texte en majuscules", "Le texte devrait Ãªtre en minuscules"
    
    def test_whitespace_normalization(self):
        """Test: Normalisation des espaces"""
        text = "Texte  avec    espaces     multiples"
        import re
        cleaned = re.sub(r'\s+', ' ', text).strip()
        
        assert cleaned == "Texte avec espaces multiples", "Les espaces multiples devraient Ãªtre normalisÃ©s"


class TestErrorHandling:
    """Tests pour la gestion des erreurs"""
    
    def test_error_403_detection(self):
        """Test: DÃ©tection de l'erreur 403"""
        error_message = "AxiosError: Request failed with status code 403"
        
        assert "403" in error_message, "L'erreur 403 devrait Ãªtre dÃ©tectÃ©e"
        assert "forbidden" in error_message.lower() or "403" in error_message, "Message d'erreur appropriÃ©"
    
    def test_file_not_found_handling(self):
        """Test: Gestion de fichier non trouvÃ©"""
        import os
        
        non_existent_file = "file_that_does_not_exist.csv"
        assert not os.path.exists(non_existent_file), "Le fichier ne devrait pas exister"
    
    def test_encoding_error_handling(self):
        """Test: Gestion des erreurs d'encodage"""
        # Simuler diffÃ©rents encodages
        encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']
        
        assert 'utf-8' in encodings, "UTF-8 devrait Ãªtre supportÃ©"
        assert len(encodings) >= 4, "Au moins 4 encodages devraient Ãªtre supportÃ©s"
    
    def test_memory_error_prevention(self):
        """Test: PrÃ©vention des erreurs mÃ©moire"""
        max_file_size = 500 * 1024 * 1024  # 500 MB
        
        # VÃ©rifier que la limite est raisonnable
        assert max_file_size == 524288000, "La limite devrait Ãªtre 500 MB"
        assert max_file_size < 1024 * 1024 * 1024, "La limite devrait Ãªtre < 1 GB"


class TestConfiguration:
    """Tests pour la configuration"""
    
    def test_server_port_configuration(self):
        """Test: Configuration du port serveur"""
        expected_port = 8502
        
        # VÃ©rifier que le port est dans une plage valide
        assert 1024 <= expected_port <= 65535, "Le port devrait Ãªtre dans une plage valide"
        assert expected_port == 8502, "Le port devrait Ãªtre 8502"
    
    def test_cors_configuration(self):
        """Test: Configuration CORS"""
        # CORS devrait Ãªtre dÃ©sactivÃ© pour le dÃ©veloppement
        cors_enabled = False
        
        assert cors_enabled == False, "CORS devrait Ãªtre dÃ©sactivÃ© en dÃ©veloppement"
    
    def test_upload_size_limit(self):
        """Test: Limite de taille d'upload"""
        max_upload_size_mb = 500
        
        assert max_upload_size_mb == 500, "La limite d'upload devrait Ãªtre 500 MB"
        assert max_upload_size_mb > 0, "La limite devrait Ãªtre positive"
    
    def test_xsrf_protection_configuration(self):
        """Test: Configuration de la protection XSRF"""
        # XSRF devrait Ãªtre dÃ©sactivÃ© pour le dÃ©veloppement
        xsrf_enabled = False
        
        assert xsrf_enabled == False, "XSRF devrait Ãªtre dÃ©sactivÃ© en dÃ©veloppement"


class TestUserInterface:
    """Tests pour l'interface utilisateur"""
    
    def test_font_awesome_icons(self):
        """Test: IcÃ´nes Font Awesome"""
        # Format d'icÃ´ne correct
        icon_html = "<i class='fas fa-robot'></i>"
        
        assert "<i class='fas fa-" in icon_html, "Format d'icÃ´ne Font Awesome correct"
        assert "</i>" in icon_html, "Balise fermante prÃ©sente"
    
    def test_stat_card_class(self):
        """Test: Classe CSS stat-card"""
        css_class = "stat-card"
        
        assert css_class == "stat-card", "Classe CSS correcte"
    
    def test_header_title_class(self):
        """Test: Classe CSS header-title"""
        css_class = "header-title"
        
        assert css_class == "header-title", "Classe CSS correcte"
    
    def test_terminology_french(self):
        """Test: Terminologie franÃ§aise"""
        # VÃ©rifier que "Claims" n'est plus utilisÃ©
        correct_term = "RÃ©clamations"
        incorrect_term = "Claims"
        
        assert correct_term == "RÃ©clamations", "Terminologie franÃ§aise correcte"
        assert correct_term != incorrect_term, "Le terme anglais ne devrait pas Ãªtre utilisÃ©"


class TestPerformance:
    """Tests pour les performances"""
    
    def test_lazy_loading_enabled(self):
        """Test: Chargement paresseux activÃ©"""
        # Simuler le chargement paresseux
        lazy_load = True
        
        assert lazy_load == True, "Le chargement paresseux devrait Ãªtre activÃ©"
    
    def test_cache_enabled(self):
        """Test: Cache activÃ©"""
        # Streamlit cache devrait Ãªtre utilisÃ©
        cache_enabled = True
        
        assert cache_enabled == True, "Le cache devrait Ãªtre activÃ©"
    
    def test_response_time_target(self):
        """Test: Objectif de temps de rÃ©ponse"""
        target_response_time = 5  # secondes
        
        assert target_response_time == 5, "L'objectif devrait Ãªtre 5 secondes"
        assert target_response_time < 10, "L'objectif devrait Ãªtre < 10 secondes"


def run_all_tests():
    """ExÃ©cuter tous les tests"""
    pytest.main([__file__, '-v', '--tb=short'])


if __name__ == "__main__":
    run_all_tests()





