"""
Configuration Centralis√©e du Syst√®me de Classification Mistral - FreeMobilaChat
=============================================================================

Module de configuration global contenant tous les param√®tres, constantes,
taxonomies et r√®gles de d√©tection pour le syst√®me de classification intelligent.

D√©velopp√© dans le cadre d'un m√©moire de master en Data Science et Intelligence Artificielle.
Ce module centralise la configuration pour faciliter la maintenance et les tests.
"""

# Imports pour la gestion des chemins et types
import os  # Acc√®s aux variables d'environnement syst√®me
from pathlib import Path  # Manipulation multi-plateforme des chemins de fichiers
from typing import Dict, List, Any  # Annotations de types pour la s√©curit√© du code

# D√©finition des chemins de base du projet (structure hi√©rarchique)
BASE_DIR = Path(__file__).parent  # R√©pertoire streamlit_app/ (racine de l'application)
SERVICES_DIR = (
    BASE_DIR / "services"
)  # R√©pertoire des modules de service (classificateurs, visualisations)
TESTS_DIR = BASE_DIR / "tests"  # R√©pertoire des tests unitaires et d'int√©gration
DATA_DIR = BASE_DIR.parent / "data"  # R√©pertoire des donn√©es (datasets, mod√®les entra√Æn√©s)

# Configuration des mod√®les de langage (LLM) avec param√®tres optimis√©s
LLM_CONFIG = {
    "ollama": {  # Configuration pour Ollama (mod√®les locaux open-source)
        "model": "llama2",  # Mod√®le par d√©faut (peut √™tre substitu√© par mistral, codellama, etc.)
        "temperature": 0.3,  # Contr√¥le de la cr√©ativit√© (0.3 = pr√©visible, 1.0 = cr√©atif)
        "max_tokens": 1000,  # Limitation de la longueur de r√©ponse pour optimiser les performances
        "timeout": 30,  # D√©lai maximal d'attente en secondes avant abandon de la requ√™te
    },
    "openai": {  # Configuration pour OpenAI GPT (API cloud payante)
        "model": "gpt-3.5-turbo",  # Mod√®le √©conomique d'OpenAI avec bon rapport qualit√©/prix
        "temperature": 0.3,  # Temp√©rature basse pour r√©ponses coh√©rentes et reproductibles
        "max_tokens": 1000,  # Limitation √©conomique des tokens g√©n√©r√©s
        "timeout": 30,  # Timeout pour √©viter les blocages sur requ√™tes lentes
    },
    "fallback": {  # Configuration du mode de secours (classification par r√®gles)
        "enabled": True,  # Activation du fallback automatique en cas d'√©chec LLM
        "confidence_threshold": 0.5,  # Seuil de confiance minimal pour accepter les r√©sultats
    },
}

# Taxonomie de classification
TAXONOMY = {
    "is_reclamation": ["OUI", "NON"],
    "theme": ["FIBRE", "MOBILE", "TV", "FACTURE", "SAV", "RESEAU", "AUTRE"],
    "sentiment": ["NEGATIF", "NEUTRE", "POSITIF"],
    "urgence": ["FAIBLE", "MOYENNE", "ELEVEE", "CRITIQUE"],
    "type_incident": ["PANNE", "LENTEUR", "FACTURATION", "PROCESSUS_SAV", "INFO", "AUTRE"],
}

# Patterns de d√©tection pour le mode fallback
DETECTION_PATTERNS = {
    "reclamation_keywords": [
        "probl√®me",
        "panne",
        "coup√©",
        "lent",
        "bug",
        "erreur",
        "dysfonctionnement",
        "insatisfait",
        "m√©content",
        "d√©√ßu",
        "frustr√©",
        "√©nerv√©",
        "col√®re",
        "r√©clamation",
        "plainte",
        "insatisfaction",
        "d√©faillance",
    ],
    "theme_fibre": [
        "fibre",
        "internet",
        "d√©bit",
        "connexion",
        "wifi",
        "box",
        "freebox",
        "ligne",
        "adsl",
        "vdsl",
        "fibre optique",
    ],
    "theme_mobile": [
        "mobile",
        "t√©l√©phone",
        "portable",
        "smartphone",
        "forfait",
        "data",
        "sms",
        "appel",
        "r√©seau mobile",
        "4g",
        "5g",
    ],
    "theme_tv": [
        "t√©l√©vision",
        "tv",
        "cha√Æne",
        "canal",
        "programme",
        "replay",
        "streaming",
        "netflix",
        "prime",
        "disney",
    ],
    "theme_facture": [
        "facture",
        "facturation",
        "prix",
        "co√ªt",
        "tarif",
        "abonnement",
        "paiement",
        "pr√©l√®vement",
        "montant",
    ],
    "theme_sav": [
        "sav",
        "service client",
        "support",
        "assistance",
        "aide",
        "technicien",
        "intervention",
        "rendez-vous",
    ],
    "theme_reseau": [
        "r√©seau",
        "infrastructure",
        "antenne",
        "couverture",
        "signal",
        "zone blanche",
        "d√©ploiement",
    ],
    "sentiment_negatif": [
        "nul",
        "horrible",
        "catastrophe",
        "d√©go√ªt√©",
        "√©nerv√©",
        "frustr√©",
        "d√©√ßu",
        "insatisfait",
        "m√©content",
        "col√®re",
        "rage",
    ],
    "sentiment_positif": [
        "super",
        "excellent",
        "g√©nial",
        "parfait",
        "content",
        "satisfait",
        "ravi",
        "heureux",
        "merci",
        "bravo",
        "f√©licitations",
    ],
    "urgence_critique": [
        "urgence",
        "critique",
        "grave",
        "bloqu√©",
        "impossible",
        "catastrophe",
        "plus rien ne fonctionne",
        "totalement coup√©",
    ],
    "urgence_elevee": [
        "depuis longtemps",
        "plusieurs heures",
        "toute la journ√©e",
        "depuis ce matin",
        "depuis hier",
        "urgent",
    ],
    "type_panne": [
        "panne",
        "coup√©",
        "ne fonctionne plus",
        "plus de service",
        "dysfonctionnement",
        "arr√™t",
    ],
    "type_lenteur": ["lent", "lenteur", "d√©bit faible", "ralentissement", "performance"],
    "type_facturation": ["facture", "facturation", "prix", "co√ªt", "tarif", "montant"],
    "type_processus_sav": ["sav", "service client", "support", "assistance", "technicien"],
}

# Configuration des types de donn√©es
DATA_TYPES = {
    "SOCIAL_MEDIA": {
        "keywords": ["tweet", "text", "message", "post"],
        "kpis": ["engagement", "sentiment", "reach"],
    },
    "ECOMMERCE": {
        "keywords": ["product", "price", "order", "customer"],
        "kpis": ["revenue", "conversion", "cart_abandonment"],
    },
    "FINANCIAL": {
        "keywords": ["amount", "balance", "transaction", "revenue"],
        "kpis": ["profit", "loss", "roi", "volatility"],
    },
    "IOT_SENSORS": {
        "keywords": ["sensor", "measurement", "value", "reading"],
        "kpis": ["data_quality", "sampling_rate", "anomalies"],
    },
    "TEMPORAL": {
        "keywords": ["date", "time", "timestamp", "hour"],
        "kpis": ["trends", "seasonality", "patterns"],
    },
}

# Configuration des m√©triques de performance
PERFORMANCE_METRICS = {
    "accuracy_threshold": 0.85,
    "confidence_threshold": 0.7,
    "processing_speed_threshold": 100,  # tweets/seconde
    "memory_limit_mb": 1000,
    "timeout_seconds": 30,
}

# Configuration des tests
TEST_CONFIG = {
    "test_tweets": [
        "@Free Internet coup√© depuis ce matin √† Marseille, aidez-moi !",
        "üì¢ Free annonce le d√©ploiement de la fibre dans 200 nouvelles communes !",
        "@Free J'attends depuis 2 semaines une r√©ponse du SAV pour ma box, toujours rien !",
        "Merci @Free pour le service client rapide et efficace !",
        "La 4G de Free fonctionne parfaitement dans ma r√©gion",
    ],
    "benchmark_volumes": [10, 50, 100, 500],
    "expected_accuracy": 0.85,
    "expected_confidence": 0.8,
}

# Configuration de l'interface Streamlit
STREAMLIT_CONFIG = {
    "page_title": "FreeMobilaChat - Classification Mistral",
    "page_icon": ":brain:",
    "layout": "wide",
    "initial_sidebar_state": "expanded",
}

# Configuration des couleurs
COLORS = {
    "primary": "#CC0000",
    "secondary": "#8B0000",
    "accent": "#FF6B6B",
    "success": "#28a745",
    "warning": "#ffc107",
    "danger": "#dc3545",
    "info": "#17a2b8",
}

# Configuration des logs
LOGGING_CONFIG = {
    "level": "INFO",
    "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    "handlers": ["file", "console"],
}

# Configuration des exports
EXPORT_CONFIG = {"csv_encoding": "utf-8", "json_indent": 2, "date_format": "%Y%m%d_%H%M%S"}

# Configuration des mod√®les
MODEL_CONFIG = {"batch_size": 100, "max_retries": 3, "retry_delay": 1, "cache_size": 1000}

# Configuration des visualisations
VISUALIZATION_CONFIG = {
    "default_width": 800,
    "default_height": 600,
    "color_scheme": "Set3",
    "animation_duration": 500,
}


def get_config() -> Dict[str, Any]:
    """Retourne la configuration compl√®te"""
    return {
        "base_dir": str(BASE_DIR),
        "services_dir": str(SERVICES_DIR),
        "tests_dir": str(TESTS_DIR),
        "data_dir": str(DATA_DIR),
        "llm_config": LLM_CONFIG,
        "taxonomy": TAXONOMY,
        "patterns": DETECTION_PATTERNS,
        "data_types": DATA_TYPES,
        "performance": PERFORMANCE_METRICS,
        "tests": TEST_CONFIG,
        "streamlit": STREAMLIT_CONFIG,
        "colors": COLORS,
        "logging": LOGGING_CONFIG,
        "export": EXPORT_CONFIG,
        "model": MODEL_CONFIG,
        "visualization": VISUALIZATION_CONFIG,
    }


def get_llm_config(provider: str = "fallback") -> Dict[str, Any]:
    """Retourne la configuration LLM pour un fournisseur"""
    return LLM_CONFIG.get(provider, LLM_CONFIG["fallback"])


def get_patterns(category: str) -> List[str]:
    """Retourne les patterns pour une cat√©gorie"""
    return DETECTION_PATTERNS.get(category, [])


def get_data_type_config(data_type: str) -> Dict[str, Any]:
    """Retourne la configuration pour un type de donn√©es"""
    return DATA_TYPES.get(data_type, {})


def is_development_mode() -> bool:
    """V√©rifie si on est en mode d√©veloppement"""
    return os.getenv("ENVIRONMENT", "development") == "development"


def get_debug_mode() -> bool:
    """V√©rifie si le mode debug est activ√©"""
    return os.getenv("DEBUG", "false").lower() == "true"


def get_log_level() -> str:
    """Retourne le niveau de log configur√©"""
    return os.getenv("LOG_LEVEL", "INFO")


def get_llm_provider() -> str:
    """Retourne le fournisseur LLM configur√©"""
    return os.getenv("LLM_PROVIDER", "fallback")


def get_llm_model() -> str:
    """Retourne le mod√®le LLM configur√©"""
    provider = get_llm_provider()
    return os.getenv("LLM_MODEL", LLM_CONFIG[provider]["model"])


# Configuration par d√©faut
DEFAULT_CONFIG = get_config()

# Export des configurations principales
__all__ = [
    "BASE_DIR",
    "SERVICES_DIR",
    "TESTS_DIR",
    "DATA_DIR",
    "LLM_CONFIG",
    "TAXONOMY",
    "DETECTION_PATTERNS",
    "DATA_TYPES",
    "PERFORMANCE_METRICS",
    "TEST_CONFIG",
    "STREAMLIT_CONFIG",
    "COLORS",
    "LOGGING_CONFIG",
    "EXPORT_CONFIG",
    "MODEL_CONFIG",
    "VISUALIZATION_CONFIG",
    "get_config",
    "get_llm_config",
    "get_patterns",
    "get_data_type_config",
    "is_development_mode",
    "get_debug_mode",
    "get_log_level",
    "get_llm_provider",
    "get_llm_model",
]
