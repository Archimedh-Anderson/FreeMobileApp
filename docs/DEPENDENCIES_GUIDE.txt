================================================================================
FreeMobilaChat - Dependencies Installation Guide
================================================================================
Version: 2.0.0
Last Updated: November 16, 2025
================================================================================

QUICK INSTALL
================================================================================

Essential Dependencies (Always Required):
-----------------------------------------
pip install streamlit pandas numpy plotly python-dotenv

Classification Dependencies (Choose based on your needs):
---------------------------------------------------------

Option 1: Full Installation (All Features)
-------------------------------------------
pip install torch transformers google-generativeai ollama

Option 2: Cloud Only (Gemini API)
---------------------------------
pip install google-generativeai

Option 3: Local Only (Mistral + BERT)
--------------------------------------
pip install torch transformers ollama

================================================================================
DETAILED DEPENDENCY INFORMATION
================================================================================

Core Framework:
---------------
streamlit>=1.32.0          # Web application framework
pandas>=2.2.1              # Data manipulation
numpy>=1.26.4              # Numerical computing
plotly>=5.19.0             # Interactive visualizations
python-dotenv>=1.0.0       # Environment configuration

Text Processing:
----------------
emoji>=2.8.0               # Emoji handling
unidecode>=1.3.0           # Unicode normalization

Classification Providers:
-------------------------

1. BERT Classifier (Deep Learning - Local):
   - torch>=2.1.0          # PyTorch framework
   - transformers>=4.34.0  # Hugging Face transformers
   
   Installation:
   pip install torch transformers
   
   Notes:
   - Requires ~2GB disk space
   - CPU version by default
   - GPU version: see PyTorch website for CUDA-enabled install

2. Mistral Classifier (LLM - Local):
   - ollama>=0.1.0         # Ollama Python client
   
   Installation:
   pip install ollama
   
   Additional Setup:
   - Download Ollama from: https://ollama.ai/download
   - Run: ollama pull mistral
   - Start service: ollama serve

3. Gemini Classifier (API - Cloud):
   - google-generativeai>=0.4.1
   
   Installation:
   pip install google-generativeai
   
   Configuration:
   - Get API key: https://makersuite.google.com/app/apikey
   - Add to .env: GEMINI_API_KEY=your_key_here

Rule-Based Classifier:
----------------------
No additional dependencies required (built-in)

================================================================================
INSTALLATION VERIFICATION
================================================================================

Verify PyTorch Installation:
-----------------------------
python -c "import torch; print('PyTorch version:', torch.__version__)"

Expected output:
PyTorch version: 2.x.x

Verify Transformers:
--------------------
python -c "import transformers; print('Transformers version:', transformers.__version__)"

Expected output:
Transformers version: 4.x.x

Verify Gemini API:
------------------
python -c "import google.generativeai as genai; print('Gemini SDK installed')"

Expected output:
Gemini SDK installed

Verify Ollama:
--------------
ollama list

Expected output:
List of downloaded models (including mistral if installed)

================================================================================
TROUBLESHOOTING
================================================================================

Issue: PyTorch installation fails
----------------------------------
Solution:
1. Try CPU-only version:
   pip install torch --index-url https://download.pytorch.org/whl/cpu

2. For Windows with GPU:
   Visit: https://pytorch.org/get-started/locally/
   Follow instructions for your CUDA version

Issue: Transformers installation fails
---------------------------------------
Solution:
1. Update pip first:
   pip install --upgrade pip

2. Install with no dependencies check:
   pip install transformers --no-deps

3. Then install dependencies:
   pip install torch

Issue: Import errors for torch/transformers
--------------------------------------------
Solution:
The application will automatically detect missing dependencies and display
a warning. Classification will fall back to rule-based and Gemini API.

Issue: Ollama connection fails
-------------------------------
Solution:
1. Check Ollama is running:
   Windows: Check Task Manager for "ollama" process
   Linux/Mac: ps aux | grep ollama

2. Start Ollama service:
   ollama serve

3. Verify connection:
   curl http://localhost:11434/api/tags

Issue: Gemini API not working
------------------------------
Solution:
1. Verify API key in .env file
2. Check for spaces/quotes around the key
3. Test key at: https://makersuite.google.com
4. Ensure internet connection is active

================================================================================
OPTIONAL DEPENDENCIES
================================================================================

Development Tools:
------------------
pip install pytest black flake8

These are only needed for development and testing, not for running the app.

================================================================================
SYSTEM REQUIREMENTS
================================================================================

Minimum:
--------
- Python 3.10+
- 4GB RAM
- 2GB disk space
- Internet (for Gemini API)

Recommended:
------------
- Python 3.11+
- 8GB RAM
- 5GB disk space
- GPU with 4GB+ VRAM (for BERT acceleration)

================================================================================
NEXT STEPS
================================================================================

After installing dependencies:
1. Copy .env.example to .env
2. Configure GEMINI_API_KEY if using Gemini
3. Start application: python -m streamlit run streamlit_app/app.py --server.port 8502
4. Access at: http://localhost:8502

For detailed deployment instructions, see:
- DEPLOYMENT_GUIDE.txt
- STREAMLIT_CLOUD_SETUP.txt

================================================================================
END OF DEPENDENCIES GUIDE
================================================================================
